{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2 as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from networkAlignmentAnalysis.models.registry import get_model\n",
    "from networkAlignmentAnalysis.datasets import get_dataset\n",
    "from networkAlignmentAnalysis.experiments.registry import get_experiment\n",
    "from networkAlignmentAnalysis import utils\n",
    "from networkAlignmentAnalysis import files\n",
    "from networkAlignmentAnalysis import train\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1.1. include additional AlignmentModel methods stored in extra class in base model\n",
    "\n",
    "# 4. Rewrite existing analysis pipelines\n",
    "# 5. SLURM!!!!\n",
    "\n",
    "# Figure out why convolutional alignment measurement is slow...\n",
    "# still working on if it's possible to speed up measure_alignment for convolutional layers\n",
    "\n",
    "# Basic alignment_comparison Analyses (or maybe for alignment_stats):\n",
    "# - compare initial to final alignment...\n",
    "# - compare initial alignment to delta weight norm...\n",
    "# - observe alignment of delta weight\n",
    "# - compare alignment to outgoing delta weight norm!\n",
    "\n",
    "# Eigenfeature analyses:\n",
    "# - Measure beta_adversarial (figure out how adversarial examples map onto eigenvectors)\n",
    "# - Determine contribution of each eigenfeature on performance with a eigenvector dropout experiment\n",
    "# ------ start by just looking at amplitude of activity on each eigenvector within each layer\n",
    "\n",
    "# alignmentShaping.ipynb has an adversarial experiment worth looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkAlignmentAnalysis.experiments.alignment_stats import AlignmentStatistics\n",
    "from argparse import ArgumentParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(network='AlexNet', dataset='MNIST', optimizer='Adam', batch_size=1024, default_lr=0.001, default_dropout=0, default_wd=0, num_drops=9, dropout_by_layer=False, epochs=10, replicates=2, use_flag=False, use_prev=True, save_ckpts=False, nosave=False, justplot=False, save_networks=False, showprms=False, showall=False, device=None, use_timestamp=False, timestamp=None)\n",
      "loaded networks from previous checkpoint\n",
      "training networks...\n",
      "resuming training from checkpoint on epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing networks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/Users/celiaberon/miniforge3/envs/networkAlignmentAnalysis/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/celiaberon/miniforge3/envs/networkAlignmentAnalysis/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [10:45<00:00, 64.60s/it]\n"
     ]
    }
   ],
   "source": [
    "expmt = AlignmentStatistics(args=['--network', 'AlexNet', '--epochs', '10', '--replicates', '2', '--use_prev'])\n",
    "\n",
    "\n",
    "# load networks \n",
    "nets, optimizers = expmt.load_networks()\n",
    "\n",
    "# load dataset\n",
    "dataset = get_dataset(expmt.args.dataset,\n",
    "                      build=True,\n",
    "                      transform_parameters=nets[0],\n",
    "                      device=expmt.args.device)\n",
    "\n",
    "# train networks\n",
    "train_results, test_results = expmt.train_networks(nets, optimizers, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_parameters = dict(num_drops=expmt.args.num_drops, by_layer=expmt.args.dropout_by_layer)\n",
    "dropout_results = train.progressive_dropout(nets, dataset, alignment=test_results['alignment'], **dropout_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(10.2166, device='cuda:0')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch: 100%|██████████| 100/100 [04:13<00:00,  2.53s/it]\n",
      "100%|██████████| 10/10 [00:00<00:00, 22.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(95.1885, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'MLP'\n",
    "dataset_name = 'MNIST'\n",
    "\n",
    "net = get_model(model_name, build=True, dataset=dataset_name).to(DEVICE)\n",
    "dataset = get_dataset(dataset_name, build=True, transform_parameters=net, device=DEVICE)\n",
    "\n",
    "init_test = train.test([net], dataset)\n",
    "print(init_test['accuracy'])\n",
    "\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "prms = dict(num_epochs=100, alignment=False, average_correlation=False)\n",
    "_ = train.train([net], [optim], dataset, **prms)\n",
    "\n",
    "post_test = train.test([net], dataset)\n",
    "print(post_test['accuracy'])\n",
    "\n",
    "beta, evals, evecs = net.measure_eigenfeatures(dataset.test_loader, with_updates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Steps: \n",
    "# - write a method to go through a dataloader and measure the contribution of each output onto the eigenvectors\n",
    "# (e.g. the average for classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
    "# out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
    "# out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n",
    "\n",
    "# out = (num_classes, num_dims, num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)\n",
    "    \n",
    "net = model()\n",
    "input = torch.normal(0, 1, (1000, 50))\n",
    "output = net(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).device.type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkAlignmentAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "145a7632351872a5cf5bac9c938322e5aecf0bbc96271ccae88ee0eac60dd862"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
